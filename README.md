# Regression-un-'notebooklm'-local

# Notebook LM (local) Â· Vision-first ToolFit

Un mini **Notebook LM local-first** (Streamlit + Ollama) qui :

- extrait ton brief et calcule un **VRS â€“ Vision Readiness Score**,
- te pose 2â€“3 **questions socratiques** pour clarifier,
- **classe les outils** (LLM, vectordb, orchestrateur, guardrails, eval) par **Time-to-MVP**,
- option **ML** : affiche **pred_p50/pred_p90** (jours) via modÃ¨les quantiles (sklearn).

> Si **VRS < 60** â†’ gating (âˆ) ; **60â€“74** â†’ pÃ©nalitÃ© ; **â‰¥ 75** â†’ GO.

---

## ğŸ‘€ Demo

Ajoute 2 captures dans `assets/` et rÃ©fÃ©rence-les ici :

- `assets/vrs_100.png` â†’ VRS = 100
- `assets/top3_ml.png` â†’ Topâ€‘3 par catÃ©gorie (ML p50/p90)

![VRS 100](assets/vrs_100.png)
![Top-3 ML](assets/top3_ml.png)

---

## ğŸš€ Quickstart

```bash
# 1) CrÃ©er l'environnement
python -m venv .venv && source .venv/bin/activate  # (Windows: .venv\Scripts\activate)

# 2) Installer
pip install -r requirements.txt

# 3) Arbo minimale
mkdir -p data artifacts config src assets

# 4) Config VRS
# thresholds: red<60, 60<=orange<75, green>=75
# alpha_penalty: 0.4 (pÃ©nalitÃ© zone orange)
# (ex de fichier)
cat > config/weights.yaml << 'YAML'
weights:
  kpi: 2.0
  kpi_target: 2.0
  data_source: 2.0
  data_format: 1.0
  data_volume: 1.0
  integration_target: 1.5
  sponsor: 1.5
  problem: 1.0
  beneficiary: 1.0
  constraints_latency: 1.0
  constraints_cost: 1.0
  constraints_security: 1.0
  usage_pattern: 1.0
  risks: 1.0
thresholds: { red: 60, orange: 75, green: 100 }
alpha_penalty: 0.4
YAML

# 5) DonnÃ©es
# Option A : utiliser les CSV d'exemple (voir plus bas)
# Option B : charger vos CSV via lâ€™uploader Streamlit

# 6) Lancer lâ€™app
streamlit run app.py
```

---

## ğŸ“¦ DonnÃ©es dâ€™exemple

Place ces fichiers dans `data/` (ou charge-les via la sidebar) :

- `data/tools.csv` (starter inclus)
- `data/contexts.csv` (synthÃ©tique)
- `data/historical_pocs.csv` (synthÃ©tique)

ğŸ‘‰ Fichiers fournis dans ce dÃ©pÃ´t (ou Ã  tÃ©lÃ©charger depuis la release) :

- `data/tools.csv` (starter)
- `data/contexts.csv` (exemple)
- `data/historical_pocs.csv` (exemple)

**SchÃ©mas rapides**

`tools.csv`

| col                                                          | type      | notes                                         |
| ------------------------------------------------------------ | --------- | --------------------------------------------- |
| tool_id                                                      | str       | identifiant unique                            |
| category                                                     | str       | llm, vectordb, orchestrator, guardrails, eval |
| open_source, api_available, self_host, json_mode, function_calling | int (0/1) | boolÃ©ens                                      |
| max_context, tok_cost_per_1k, avg_latency_ms, req_gpu_mem_gb | num       | estimations ok                                |
| fr_quality                                                   | str       | low/mid/high                                  |
| index_type                                                   | str       | (vectordb) ex. ivf_flat, hnsw                 |
| complexity_level                                             | int       | 1=low, 2=mid, 3=high                          |

`contexts.csv`
| poc_id | VRS | latency_ms_budget | budget_eur | infra | lang_fr | â€¦ |

`historical_pocs.csv`
| poc_id | tool_id | time_to_mvp_days |

---

## ğŸ§  Mode ML (p50/p90)

Les modÃ¨les (sklearn GradientBoosting, quantiles 0.5 & 0.9) sont chargÃ©s depuis `artifacts/` :

```
artifacts/
â”œâ”€ gbm_p50.joblib
â”œâ”€ gbm_p90.joblib
â””â”€ feature_meta.json
```

> Pour entraÃ®ner vos propres modÃ¨les, utilisez le script `notebooks/` ou le gÃ©nÃ©rateur synthÃ©tique fourni (voir release / docs).

Dans lâ€™onglet **Recommandations**, coche â€œUtiliser le modÃ¨le ML (p50/p90)â€ ou utilisez la CLI :

```bash
python -m src.predict --context data/contexts.csv --tools data/tools.csv --poc_id POC001 --topk 3
```

---

## ğŸ—‚ï¸ Arborescence

```
.
â”œâ”€ app.py
â”œâ”€ src/
â”‚  â”œâ”€ vrs_extractor.py      # extraction champs via LLM local (Ollama)
â”‚  â”œâ”€ vrs_score.py          # calcul VRS + rÃ¨gles
â”‚  â”œâ”€ socratic.py           # questions guidÃ©es
â”‚  â”œâ”€ ranking.py            # heuristique Time-to-MVP
â”‚  â”œâ”€ predict_ml.py         # infÃ©rence p50/p90
â”‚  â””â”€ predict.py            # CLI scoring
â”œâ”€ data/
â”‚  â”œâ”€ tools.csv
â”‚  â”œâ”€ contexts.csv
â”‚  â””â”€ historical_pocs.csv
â”œâ”€ artifacts/
â”‚  â”œâ”€ gbm_p50.joblib
â”‚  â”œâ”€ gbm_p90.joblib
â”‚  â””â”€ feature_meta.json
â”œâ”€ config/
â”‚  â””â”€ weights.yaml
â””â”€ assets/
   â”œâ”€ vrs_100.png
   â””â”€ top3_ml.png
```

---

## ğŸ”§ Variables utiles

- `LLM_MODEL` (env) : modÃ¨le Ollama (par dÃ©faut `mistral:instruct`)
- `OLLAMA_URL` (env) : `http://localhost:11434`

---

## ğŸ“œ Licence

MIT â€” voir `LICENSE`.

---

## ğŸ—ºï¸ Roadmap

- [ ] Feature importance + SHAP locales (explicabilitÃ© ML)  
- [ ] Bench latence local (remplir auto `avg_latency_ms`)  
- [ ] Connecteurs (Git, Confluence) pour ingestion doc  
- [ ] Export PDF du rapport

---

## ğŸ™Œ CrÃ©dits

ConÃ§u pour aider Ã  **sÃ©curiser la vision** avant la stack. Local-first, FR-ready.
